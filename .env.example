# Server Configuration
PORT=3333

# Authentication (leave empty to disable)
BEARER_TOKEN=your-secret-api-key-here

# n8n Configuration
N8N_WEBHOOK_BEARER_TOKEN=

# Models Configuration
# MODEL_LOADER_TYPE: "file" (default), "n8n-api", or "static"
MODEL_LOADER_TYPE=file

# File Loader Configuration (when MODEL_LOADER_TYPE=file)
MODELS_CONFIG_FILE=./models.json
# MODELS_WATCH_INTERVAL=1000  # File polling interval in ms (default: 1000)
# MODELS_CONFIG=./models.json  # (deprecated, use MODELS_CONFIG_FILE instead)

# n8n API Loader Configuration (when MODEL_LOADER_TYPE=n8n-api)
# N8N_BASE_URL=https://your-n8n-instance.com
# N8N_API_BEARER_TOKEN=n8n_api_xxxxxxxxxxxxx
# AUTO_DISCOVERY_TAG=n8n-openai-bridge
# AUTO_DISCOVERY_POLLING=300

# Static Loader Configuration (when MODEL_LOADER_TYPE=static, testing only)
# STATIC_MODELS={"test-model":"https://n8n.example.com/webhook/test"}

# Logging (set to 'true' to enable detailed request logging)
LOG_REQUESTS=false

# Session ID Headers (comma-separated list, first found wins)
SESSION_ID_HEADERS=X-Session-Id,X-Chat-Id,X-OpenWebUI-Chat-Id

# User Information Headers (comma-separated list, first found wins)
USER_ID_HEADERS=X-User-Id,X-OpenWebUI-User-Id
USER_EMAIL_HEADERS=X-User-Email,X-OpenWebUI-User-Email
USER_NAME_HEADERS=X-User-Name,X-OpenWebUI-User-Name
USER_ROLE_HEADERS=X-User-Role,X-OpenWebUI-User-Role

# Rate Limiting Configuration
# RATE_LIMIT_WINDOW_MS=60000           # Time window in milliseconds (default: 1 minute)
# RATE_LIMIT_MAX_REQUESTS=100          # Max requests per window (default: 100)
# RATE_LIMIT_CHAT_COMPLETIONS=30       # Max chat completions per window (default: 30)
# DISABLE_RATE_LIMIT=false             # Set to 'true' to disable rate limiting
